{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4acbebf",
      "metadata": {
        "id": "b4acbebf"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "data = datasets.load_dataset('squad_v2')\n",
        "train_dataset, test_dataset = data['train'], data['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10975a0e",
      "metadata": {
        "id": "10975a0e"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f86ed41d",
      "metadata": {
        "id": "f86ed41d"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer, DataCollatorForSeq2Seq\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae653867",
      "metadata": {
        "id": "ae653867"
      },
      "outputs": [],
      "source": [
        "special_tokens_dict = {'additional_special_tokens': ['<|title|>', '<|question|>', '<|answer|>', '<|context|>']}\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7987543c",
      "metadata": {
        "id": "7987543c"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "new_train, new_test = {'context': [], 'questions': [], 'answers': [], 'title': []}, {'context': [], 'questions': [], 'answers': [], 'title': []}\n",
        "\n",
        "contexts, questions, answers, titles = train_dataset['context'], train_dataset['question'], train_dataset['answers'], train_dataset['title']\n",
        "for i in tqdm.tqdm(range(len(train_dataset['id']))):\n",
        "    if len(answers[i]['text']) == 0:\n",
        "        continue\n",
        "\n",
        "    context, question, answer, title = contexts[i], questions[i], answers[i]['text'][0], titles[i]\n",
        "\n",
        "    if title.lower() not in question.lower() or title.lower() in answer.lower():\n",
        "       continue\n",
        "\n",
        "    if len(new_train['context']) > 0 and new_train['context'][-1] == context:\n",
        "        new_train['questions'][-1].append(question)\n",
        "        new_train['answers'][-1].append(answer)\n",
        "    else:\n",
        "        new_train['questions'].append([question])\n",
        "        new_train['answers'].append([answer])\n",
        "        new_train['title'].append(title)\n",
        "        new_train['context'].append(context)\n",
        "\n",
        "contexts, questions, answers, titles = test_dataset['context'], test_dataset['question'], test_dataset['answers'], test_dataset['title']\n",
        "for i in tqdm.tqdm(range(len(test_dataset['id']))):\n",
        "    if len(answers[i]['text']) == 0:\n",
        "        continue\n",
        "\n",
        "    context, question, answer, title = contexts[i], questions[i], answers[i]['text'][0], titles[i]\n",
        "\n",
        "    if len(new_test['context']) > 0 and new_test['context'][-1] == context:\n",
        "        new_test['questions'][-1].append(question)\n",
        "        new_test['answers'][-1].append(answer)\n",
        "    else:\n",
        "        new_test['questions'].append([question])\n",
        "        new_test['answers'].append([answer])\n",
        "        new_test['title'].append(title)\n",
        "        new_test['context'].append(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63a399ad",
      "metadata": {
        "id": "63a399ad"
      },
      "outputs": [],
      "source": [
        "train_ds, test_ds = datasets.Dataset.from_dict(new_train), datasets.Dataset.from_dict(new_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bcfc326",
      "metadata": {
        "id": "0bcfc326"
      },
      "outputs": [],
      "source": [
        "max_input_length = 512\n",
        "max_target_length = 512\n",
        "def preprocess_function(examples):\n",
        "    inputs = [\"<|title|> \" + examples['title'][i] + \" <|context|> \" + examples['context'][i] for i in range(len(examples[\"context\"]))]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer([' '.join([\"<|answer|> \" + examples[\"answers\"][j][i] + \" <|question|> \" + examples['questions'][j][i] for i in range(len(examples['questions'][j]))]) for j in range(len(examples['questions']))], max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e1643d9",
      "metadata": {
        "id": "4e1643d9"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "meteor = evaluate.load('meteor')\n",
        "bleu = evaluate.load('bleu')\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "    rouge_output2 = rouge.compute(predictions=decoded_preds, references=decoded_labels, rouge_types=[\"rouge2\"])[\"rouge2\"]\n",
        "    rouge_output1 = rouge.compute(predictions=decoded_preds, references=decoded_labels, rouge_types=[\"rouge1\"])[\"rouge1\"]\n",
        "    bleu_vals = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    meteor_vals = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    return {\n",
        "        \"rouge1\": rouge_output1,\n",
        "        \"rouge2\": rouge_output2,\n",
        "        \"meteor\": meteor_vals['meteor'],\n",
        "        \"blue\": bleu_vals['bleu']\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79e931e4",
      "metadata": {
        "id": "79e931e4"
      },
      "outputs": [],
      "source": [
        "train_dataset_tok = train_ds.map(preprocess_function, batched=True)\n",
        "test_dataset_tok = test_ds.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3bb7975",
      "metadata": {
        "id": "a3bb7975"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"question-generator\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy='no',\n",
        "    num_train_epochs=5,\n",
        "    warmup_steps=500,\n",
        "    predict_with_generate=True,\n",
        "    gradient_accumulation_steps=8,\n",
        "    logging_steps=100\n",
        ")\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset_tok,\n",
        "    eval_dataset=test_dataset_tok,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfe95679",
      "metadata": {
        "id": "dfe95679"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae787a07",
      "metadata": {
        "id": "ae787a07"
      },
      "outputs": [],
      "source": [
        "out_dir = ''\n",
        "trainer.push_to_hub(out_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}